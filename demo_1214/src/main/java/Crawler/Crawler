package crawler;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;

import java.io.IOException;
import java.util.ArrayList;
import java.util.List;

public class Crawler{
    
    private List<String> urls;

    public Crawler(List<String> urls) {
        this.urls = urls;
    }

    public List<String> fetchData() {
        List<String> htmlList = new ArrayList<>();
        for (String url : urls) {
            try {
                Document doc = Jsoup.connect(url).get();
                htmlList.add(doc.html());
            } catch (IOException e) {
                System.err.println("Failed to fetch URL: " + url);
            }
        }
        return htmlList;
    }
}
